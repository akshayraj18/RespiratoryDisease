{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import librosa as librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "%matplotlib inline\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "import time\n",
    "import gc\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6898 cycles\n",
      "There are 920 samples\n"
     ]
    }
   ],
   "source": [
    "directory_path = 'data/Respiratory_Sound_Database/audio_and_txt_files'\n",
    "text_files = glob.iglob(directory_path + '/*.txt', recursive=True)\n",
    "text_files_list = list(text_files)\n",
    "\n",
    "dfs = []\n",
    "for file in text_files_list:\n",
    "    content = pd.read_csv(file, names = [\"start_time\", \"end_time\", \"crackles\", \"wheezes\"], delimiter = \"\\t\")\n",
    "    patient_number = file.split(\"_\")[5][6:]\n",
    "    content['patient'] = int(patient_number)\n",
    "    dfs.append(content)\n",
    "samples = pd.concat(dfs)\n",
    "\n",
    "print(\"There are\", len(samples), \"cycles\")\n",
    "print(\"There are\", len(text_files_list), \"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new directories to be created\n",
    "spectrograms_path = \"data/spectrograms\"\n",
    "clips_by_cycle_path = \"data/Respiratory_Sound_Database/clips_by_cycle\"\n",
    "\n",
    "# create the directories\n",
    "os.makedirs(spectrograms_path, exist_ok=True)\n",
    "os.makedirs(clips_by_cycle_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of data/spectrograms cleared.\n",
      "Contents of data/Respiratory_Sound_Database/clips_by_cycle cleared.\n"
     ]
    }
   ],
   "source": [
    "# clear output of folders created above\n",
    "output_folders = ['data/spectrograms','data/Respiratory_Sound_Database/clips_by_cycle']\n",
    "for folder in output_folders:\n",
    "    for file_name in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, file_name)\n",
    "        # Remove the file\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "\n",
    "    print(f\"Contents of {folder} cleared.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'data/spectrograms'\n",
    "# converts file, where file is a string (name of the file), into a string with the given format, where format is a string\n",
    "# assumes the format already in the file is 3 characters long\n",
    "# if cycle > 0, it adds \"cycle _\" to the end of the file name before the ending\n",
    "# if cycle = 0, it leaves the rest of the file as is\n",
    "def convert_type(file, format, cycle):\n",
    "    if cycle > 0:\n",
    "        file = file[0:len(file)-4] + \"_cycle\" + str(cycle) + \".\" + format\n",
    "    else:\n",
    "        file = file[0:len(file)-3] + format\n",
    "    return file\n",
    "\n",
    "\n",
    "# divide audio_file into its respiratory cycles\n",
    "# takes the name of the audio file (.wav) as a string as the argument\n",
    "def divide_into_cycles(audio_file_name):\n",
    "    # take just the timestamps for the respiratory cycles- ignore crackles and wheezes\n",
    "    audio_file_name_as_txt = directory_path + \"/\" + convert_type(audio_file_name, \"txt\", 0)\n",
    "    timestamps = np.loadtxt(audio_file_name_as_txt, delimiter='\\t')\n",
    "    timestamps = timestamps[:, :2]\n",
    "    \n",
    "    return timestamps\n",
    "\n",
    "\n",
    "def generate_spectrogram(audio_file):\n",
    "    # load the audio file\n",
    "    y, sr = librosa.load(audio_file)\n",
    "    \n",
    "    audio_file_name = os.path.basename(audio_file)\n",
    "    # find where the timestamps of audio_file are\n",
    "    timestamps = divide_into_cycles(audio_file_name) # list\n",
    "    \n",
    "    # find the length of the shortest spectrogram\n",
    "    min = -1\n",
    "    for cycle in timestamps:\n",
    "        start_time = cycle[0]\n",
    "        end_time = cycle[1]\n",
    "        length = end_time - start_time\n",
    "        if min == -1 or length < min:\n",
    "            min = length\n",
    "    \n",
    "    # make a mel db spectrogram for each respiratory cycle using the timestamps\n",
    "    cycle_number = 1\n",
    "    for cycle in timestamps:\n",
    "        # take the portion of the audio that contains this respiratory cycle\n",
    "\n",
    "        # start and end time in seconds\n",
    "        start_time = cycle[0]\n",
    "        end_time = cycle[1]\n",
    "        \n",
    "        # determine how much of the audio segment we need to crop\n",
    "        diff = (end_time - start_time) - min\n",
    "        crop_amt = int(diff / 2)\n",
    "        \n",
    "        # convert the start and end times to sample indices\n",
    "        start_sample = int(start_time * sr) + crop_amt\n",
    "        end_sample = int(end_time * sr) - crop_amt\n",
    "        \n",
    "        # extract the audio segment\n",
    "        audio_segment = y[start_sample:end_sample]\n",
    "        \n",
    "        spectrogram_name = convert_type(audio_file_name, \"jpg\", cycle_number)\n",
    "        \n",
    "        # make the mel db spectrogram based on that audio segment\n",
    "        D = librosa.amplitude_to_db(np.abs(librosa.stft(audio_segment, n_fft=2048, hop_length=512)), ref=np.max)\n",
    "        # display the spectrogram\n",
    "        plt.figure(figsize=(5, 2))\n",
    "        librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', cmap='viridis')\n",
    "        plt.axis('off')\n",
    "        plt.subplots_adjust(left=0, right=1, top=1, bottom=0) # removes the white space around the spectrogram\n",
    "        # plt.colorbar(format='%+2.0f dB')\n",
    "        # plt.title(spectrogram_name)\n",
    "\n",
    "        # save the spectrogram to the output folder\n",
    "        output_path = os.path.join(output_folder, spectrogram_name)\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "        \n",
    "        cycle_number += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets all audio files\n",
    "audio_files = glob.iglob(directory_path + '/*.wav', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 files so far in 7.259006977081299 seconds\n",
      "Processed 20 files so far in 12.949694156646729 seconds\n",
      "Processed 30 files so far in 18.49913501739502 seconds\n",
      "Processed 40 files so far in 23.17435598373413 seconds\n",
      "Processed 50 files so far in 28.049819946289062 seconds\n",
      "Processed 60 files so far in 32.719929933547974 seconds\n",
      "Processed 70 files so far in 37.45670413970947 seconds\n",
      "Processed 80 files so far in 42.31224203109741 seconds\n",
      "Processed 90 files so far in 47.224157094955444 seconds\n",
      "Processed 100 files so far in 53.2026629447937 seconds\n",
      "Processed 110 files so far in 58.240259885787964 seconds\n",
      "Processed 120 files so far in 62.98455500602722 seconds\n",
      "Processed 130 files so far in 67.77461194992065 seconds\n",
      "Processed 140 files so far in 72.40822100639343 seconds\n",
      "Processed 150 files so far in 77.31137895584106 seconds\n",
      "Processed 160 files so far in 83.61608004570007 seconds\n",
      "Processed 170 files so far in 88.72831797599792 seconds\n",
      "Processed 180 files so far in 93.67594408988953 seconds\n",
      "Processed 190 files so far in 99.72314810752869 seconds\n",
      "Processed 200 files so far in 104.38344097137451 seconds\n",
      "Processed 210 files so far in 110.55489420890808 seconds\n",
      "Processed 220 files so far in 115.37441325187683 seconds\n",
      "Processed 230 files so far in 121.79114007949829 seconds\n",
      "Processed 240 files so far in 126.83957624435425 seconds\n",
      "Processed 250 files so far in 132.13262295722961 seconds\n",
      "Processed 260 files so far in 138.1747419834137 seconds\n",
      "Processed 270 files so far in 144.31637620925903 seconds\n",
      "Processed 280 files so far in 149.28977417945862 seconds\n",
      "Processed 290 files so far in 154.63856315612793 seconds\n",
      "Processed 300 files so far in 159.97731518745422 seconds\n",
      "Processed 310 files so far in 165.37053108215332 seconds\n",
      "Processed 320 files so far in 170.38138914108276 seconds\n",
      "Processed 330 files so far in 175.54629111289978 seconds\n",
      "Processed 340 files so far in 180.90291905403137 seconds\n",
      "Processed 350 files so far in 187.12105703353882 seconds\n",
      "Processed 360 files so far in 192.28483629226685 seconds\n",
      "Processed 370 files so far in 197.68828916549683 seconds\n",
      "Processed 380 files so far in 203.1885221004486 seconds\n",
      "Processed 390 files so far in 209.93648409843445 seconds\n",
      "Processed 400 files so far in 215.51638317108154 seconds\n",
      "Processed 410 files so far in 220.86236119270325 seconds\n",
      "Processed 420 files so far in 227.37707495689392 seconds\n",
      "Processed 430 files so far in 234.0905430316925 seconds\n",
      "Processed 440 files so far in 240.01541209220886 seconds\n",
      "Processed 450 files so far in 245.73929905891418 seconds\n",
      "Processed 460 files so far in 251.2446129322052 seconds\n",
      "Processed 470 files so far in 256.92882323265076 seconds\n",
      "Processed 480 files so far in 263.67367005348206 seconds\n",
      "Processed 490 files so far in 268.9734389781952 seconds\n",
      "Processed 500 files so far in 274.9174122810364 seconds\n",
      "Processed 510 files so far in 280.43971991539 seconds\n",
      "Processed 520 files so far in 286.4946811199188 seconds\n",
      "Processed 530 files so far in 294.12661504745483 seconds\n",
      "Processed 540 files so far in 299.6035621166229 seconds\n",
      "Processed 550 files so far in 305.4305911064148 seconds\n",
      "Processed 560 files so far in 310.98544001579285 seconds\n",
      "Processed 570 files so far in 317.8301420211792 seconds\n",
      "Processed 580 files so far in 323.753625869751 seconds\n",
      "Processed 590 files so far in 329.302698135376 seconds\n",
      "Processed 600 files so far in 335.5206151008606 seconds\n",
      "Processed 610 files so far in 341.22000908851624 seconds\n",
      "Processed 620 files so far in 347.37729001045227 seconds\n",
      "Processed 630 files so far in 353.865021944046 seconds\n",
      "Processed 640 files so far in 360.7131130695343 seconds\n",
      "Processed 650 files so far in 366.60916900634766 seconds\n",
      "Processed 660 files so far in 374.04180788993835 seconds\n",
      "Processed 670 files so far in 380.5310549736023 seconds\n",
      "Processed 680 files so far in 386.74472999572754 seconds\n",
      "Processed 690 files so far in 393.9622640609741 seconds\n",
      "Processed 700 files so far in 401.2688720226288 seconds\n",
      "Processed 710 files so far in 407.88961911201477 seconds\n",
      "Processed 720 files so far in 415.53859519958496 seconds\n",
      "Processed 730 files so far in 422.263023853302 seconds\n",
      "Processed 740 files so far in 430.136647939682 seconds\n",
      "Processed 750 files so far in 436.5271911621094 seconds\n",
      "Processed 760 files so far in 442.95960807800293 seconds\n",
      "Processed 770 files so far in 449.59229707717896 seconds\n",
      "Processed 780 files so far in 456.3099410533905 seconds\n",
      "Processed 790 files so far in 463.93681502342224 seconds\n",
      "Processed 800 files so far in 470.93615102767944 seconds\n",
      "Processed 810 files so far in 477.727108001709 seconds\n",
      "Processed 820 files so far in 484.50313806533813 seconds\n",
      "Processed 830 files so far in 491.1811988353729 seconds\n",
      "Processed 840 files so far in 498.10174798965454 seconds\n",
      "Processed 850 files so far in 506.53614497184753 seconds\n",
      "Processed 860 files so far in 513.4334890842438 seconds\n",
      "Processed 870 files so far in 520.4761550426483 seconds\n",
      "Processed 880 files so far in 528.1961889266968 seconds\n",
      "Processed 890 files so far in 535.132040977478 seconds\n",
      "Processed 900 files so far in 542.4019939899445 seconds\n",
      "Processed 910 files so far in 549.5555431842804 seconds\n",
      "Processed 920 files so far in 556.7373239994049 seconds\n",
      "Processed a batch of 920 files in 559.2181270122528 seconds\n"
     ]
    }
   ],
   "source": [
    "#creates spectrograms from audio files using generate_spectrogram\n",
    "begin_time = time.time()\n",
    "file_number = 0\n",
    "\n",
    "for audio_file in audio_files:\n",
    "    generate_spectrogram(audio_file)\n",
    "    file_number += 1\n",
    "\n",
    "    # Print progress\n",
    "    if file_number % 10 == 0:\n",
    "        print(f\"Processed {file_number} files so far in {time.time() - begin_time} seconds\")\n",
    "        gc.collect()\n",
    "\n",
    "print(f\"Processed a batch of {file_number} files in {time.time() - begin_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to generate audio clips by cycle\n",
    "def generate_audio_clips(audio_file, output_folder):\n",
    "    # load the audio file\n",
    "    y, sr = librosa.load(audio_file)\n",
    "    \n",
    "    audio_file_name = os.path.basename(audio_file)\n",
    "    # find where the timestamps of audio_file are\n",
    "    timestamps = divide_into_cycles(audio_file_name) # list\n",
    "    \n",
    "    # make an audio clip for each respiratory cycle using the timestamps\n",
    "    cycle_number = 1\n",
    "    for cycle in timestamps:\n",
    "        # take the portion of the audio that contains this respiratory cycle\n",
    "\n",
    "        # start and end time in seconds\n",
    "        start_time = cycle[0]\n",
    "        end_time = cycle[1]\n",
    "        \n",
    "        # convert the start and end times to sample indices\n",
    "        start_sample = int(start_time * sr)\n",
    "        end_sample = int(end_time * sr)\n",
    "        \n",
    "        # extract the audio segment\n",
    "        audio_segment = y[start_sample:end_sample]\n",
    "        \n",
    "        audio_clip_name = convert_type(audio_file_name, \"wav\", cycle_number)\n",
    "        \n",
    "        # save the audio clip to the output folder\n",
    "        output_path = os.path.join(output_folder, audio_clip_name)\n",
    "        write(output_path, sr, audio_segment)\n",
    "        \n",
    "        cycle_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = 'data/Respiratory_Sound_Database/audio_and_txt_files'\n",
    "output_folder = 'data/Respiratory_Sound_Database/clips_by_cycle'\n",
    "\n",
    "audio_files = glob.iglob(directory_path + '/*.wav', recursive=True)\n",
    "\n",
    "#generates cut audio clips by cycle and puts them in clips_by_cycle folder\n",
    "for audio_file in audio_files:\n",
    "    generate_audio_clips(audio_file, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            filename  \\\n",
      "0      215_1b3_Tc_sc_Meditron_cycle6   \n",
      "1      178_1b2_Al_mc_AKGC417L_cycle7   \n",
      "2     120_1b1_Pl_sc_Meditron_cycle16   \n",
      "3      166_1p1_Pl_sc_Meditron_cycle4   \n",
      "4      200_3p4_Pr_mc_AKGC417L_cycle2   \n",
      "...                              ...   \n",
      "6893   138_1p3_Tc_mc_AKGC417L_cycle4   \n",
      "6894   131_1b1_Al_sc_Meditron_cycle8   \n",
      "6895   216_1b1_Pl_sc_Meditron_cycle1   \n",
      "6896  222_1b1_Lr_sc_Meditron_cycle11   \n",
      "6897   186_2b3_Tc_mc_AKGC417L_cycle4   \n",
      "\n",
      "                                             sound_file  \\\n",
      "0     data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "1     data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "2     data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "3     data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "4     data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "...                                                 ...   \n",
      "6893  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "6894  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "6895  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "6896  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "6897  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "\n",
      "                                       spectrogram_file  \n",
      "0     data/spectrograms/215_1b3_Tc_sc_Meditron_cycle...  \n",
      "1     data/spectrograms/178_1b2_Al_mc_AKGC417L_cycle...  \n",
      "2     data/spectrograms/120_1b1_Pl_sc_Meditron_cycle...  \n",
      "3     data/spectrograms/166_1p1_Pl_sc_Meditron_cycle...  \n",
      "4     data/spectrograms/200_3p4_Pr_mc_AKGC417L_cycle...  \n",
      "...                                                 ...  \n",
      "6893  data/spectrograms/138_1p3_Tc_mc_AKGC417L_cycle...  \n",
      "6894  data/spectrograms/131_1b1_Al_sc_Meditron_cycle...  \n",
      "6895  data/spectrograms/216_1b1_Pl_sc_Meditron_cycle...  \n",
      "6896  data/spectrograms/222_1b1_Lr_sc_Meditron_cycle...  \n",
      "6897  data/spectrograms/186_2b3_Tc_mc_AKGC417L_cycle...  \n",
      "\n",
      "[6898 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# get the list of sound files\n",
    "sound_files = glob.glob('data/Respiratory_Sound_Database/clips_by_cycle/*.wav')\n",
    "\n",
    "# get the list of spectrogram files\n",
    "spectrogram_files = glob.glob('data/spectrograms/*.jpg')\n",
    "\n",
    "# create a DataFrame for sound files\n",
    "df_sound = pd.DataFrame({\n",
    "    'filename': [os.path.splitext(os.path.basename(x))[0] for x in sound_files],\n",
    "    'sound_file': sound_files\n",
    "})\n",
    "\n",
    "# create a DataFrame for spectrogram files\n",
    "df_spectrogram = pd.DataFrame({\n",
    "    'filename': [os.path.splitext(os.path.basename(x))[0] for x in spectrogram_files],\n",
    "    'spectrogram_file': spectrogram_files\n",
    "})\n",
    "\n",
    "# merge the DataFrames on the 'filename' column\n",
    "df = pd.merge(df_sound, df_spectrogram, on='filename')\n",
    "\n",
    "# print the DataFrame\n",
    "print(df)\n",
    "\n",
    "#df now contains filename, sound_file, and spectrogram_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data=pd.read_csv('data/Respiratory_Sound_Database/patient_diagnosis.csv',names=['pid','disease'])\n",
    "path='data/Respiratory_Sound_Database/audio_and_txt_files/'\n",
    "files=[s.split('.')[0] for s in os.listdir(path) if '.txt' in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilenameInfo(file):\n",
    "    return file.split('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_data=[]\n",
    "for file in files:\n",
    "    data=pd.read_csv(path + file + '.txt',sep='\\t',names=['start','end','crackles','wheezes'])\n",
    "    name_data=getFilenameInfo(file)\n",
    "    data['pid']=name_data[0]\n",
    "    data['mode']=name_data[-2]\n",
    "    data['filename']=file\n",
    "    files_data.append(data)\n",
    "files_df=pd.concat(files_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         filename  \\\n",
      "0   215_1b3_Tc_sc_Meditron_cycle6   \n",
      "1   178_1b2_Al_mc_AKGC417L_cycle7   \n",
      "2  120_1b1_Pl_sc_Meditron_cycle16   \n",
      "3   166_1p1_Pl_sc_Meditron_cycle4   \n",
      "4   200_3p4_Pr_mc_AKGC417L_cycle2   \n",
      "\n",
      "                                          sound_file  \\\n",
      "0  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "1  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "2  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "3  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "4  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "\n",
      "                                    spectrogram_file  \n",
      "0  data/spectrograms/215_1b3_Tc_sc_Meditron_cycle...  \n",
      "1  data/spectrograms/178_1b2_Al_mc_AKGC417L_cycle...  \n",
      "2  data/spectrograms/120_1b1_Pl_sc_Meditron_cycle...  \n",
      "3  data/spectrograms/166_1p1_Pl_sc_Meditron_cycle...  \n",
      "4  data/spectrograms/200_3p4_Pr_mc_AKGC417L_cycle...  \n",
      "   start    end  crackles  wheezes  pid mode                filename disease\n",
      "0  0.022  0.364         0        0  148   sc  148_1b1_Al_sc_Meditron    URTI\n",
      "1  0.364  2.436         0        0  148   sc  148_1b1_Al_sc_Meditron    URTI\n",
      "2  2.436  4.636         0        0  148   sc  148_1b1_Al_sc_Meditron    URTI\n",
      "3  4.636  6.793         0        0  148   sc  148_1b1_Al_sc_Meditron    URTI\n",
      "4  6.793  8.750         0        0  148   sc  148_1b1_Al_sc_Meditron    URTI\n"
     ]
    }
   ],
   "source": [
    "patient_data.pid=patient_data.pid.astype('int32')\n",
    "files_df.pid=files_df.pid.astype('int32')\n",
    "data=pd.merge(files_df,patient_data,on='pid')\n",
    "print(df.head())\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       start     end  crackles  wheezes  pid mode         disease  \\\n",
      "0      0.022   0.364         0        0  148   sc            URTI   \n",
      "1      0.364   2.436         0        0  148   sc            URTI   \n",
      "2      2.436   4.636         0        0  148   sc            URTI   \n",
      "3      4.636   6.793         0        0  148   sc            URTI   \n",
      "4      6.793   8.750         0        0  148   sc            URTI   \n",
      "...      ...     ...       ...      ...  ...  ...             ...   \n",
      "6893  16.946  19.156         1        0  130   mc            COPD   \n",
      "6894   0.022   3.450         0        0  116   sc  Bronchiectasis   \n",
      "6895   3.450  10.507         0        1  116   sc  Bronchiectasis   \n",
      "6896  10.507  17.336         0        1  116   sc  Bronchiectasis   \n",
      "6897  17.336  19.950         0        0  116   sc  Bronchiectasis   \n",
      "\n",
      "                           filename  cycle_number  \n",
      "0     148_1b1_Al_sc_Meditron_cycle1             1  \n",
      "1     148_1b1_Al_sc_Meditron_cycle2             2  \n",
      "2     148_1b1_Al_sc_Meditron_cycle3             3  \n",
      "3     148_1b1_Al_sc_Meditron_cycle4             4  \n",
      "4     148_1b1_Al_sc_Meditron_cycle5             5  \n",
      "...                             ...           ...  \n",
      "6893  130_2b3_Al_mc_AKGC417L_cycle9             9  \n",
      "6894  116_1b2_Pl_sc_Meditron_cycle1             1  \n",
      "6895  116_1b2_Pl_sc_Meditron_cycle2             2  \n",
      "6896  116_1b2_Pl_sc_Meditron_cycle3             3  \n",
      "6897  116_1b2_Pl_sc_Meditron_cycle4             4  \n",
      "\n",
      "[6898 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# create a new column 'filename_cycle'\n",
    "data['filename_cycle'] = data.groupby('filename').cumcount() + 1\n",
    "\n",
    "# concatenate 'filename' and 'filename_cycle' to create a new column\n",
    "data['filename_cycle'] = data['filename'] + '_cycle' + data['filename_cycle'].astype(str)\n",
    "\n",
    "data['cycle_number'] = data['filename_cycle'].apply(lambda x: int(x.split('_cycle')[-1]))\n",
    "\n",
    "data = data.drop('filename', axis=1)\n",
    "\n",
    "# rename the 'filename_cycle' column to 'filename'\n",
    "data = data.rename(columns={'filename_cycle': 'filename'})\n",
    "\n",
    "# print the DataFrame\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            filename  pid  cycle_number   start     end  \\\n",
      "2013   101_1b1_Pr_sc_Meditron_cycle1  101             1   0.036   1.264   \n",
      "6070   101_1b1_Al_sc_Meditron_cycle1  101             1   0.036   0.579   \n",
      "2433   101_1b1_Pr_sc_Meditron_cycle2  101             2   1.264   3.422   \n",
      "6504   101_1b1_Al_sc_Meditron_cycle2  101             2   0.579   2.450   \n",
      "2333   101_1b1_Pr_sc_Meditron_cycle3  101             3   3.422   5.550   \n",
      "...                              ...  ...           ...     ...     ...   \n",
      "6792   226_1b1_Al_sc_Meditron_cycle9  226             9  15.907  18.307   \n",
      "233   226_1b1_Al_sc_Meditron_cycle10  226            10  18.307  19.964   \n",
      "3073  226_1b1_Ll_sc_Meditron_cycle10  226            10  17.964  19.950   \n",
      "4475  226_1b1_Pl_sc_LittC2SE_cycle10  226            10  17.493  19.436   \n",
      "4487  226_1b1_Pl_sc_LittC2SE_cycle11  226            11  19.436  19.979   \n",
      "\n",
      "      crackles  wheezes mode    disease  \\\n",
      "2013         0        0   sc       URTI   \n",
      "6070         0        0   sc       URTI   \n",
      "2433         0        0   sc       URTI   \n",
      "6504         0        0   sc       URTI   \n",
      "2333         0        0   sc       URTI   \n",
      "...        ...      ...  ...        ...   \n",
      "6792         0        0   sc  Pneumonia   \n",
      "233          0        0   sc  Pneumonia   \n",
      "3073         0        0   sc  Pneumonia   \n",
      "4475         1        0   sc  Pneumonia   \n",
      "4487         0        0   sc  Pneumonia   \n",
      "\n",
      "                                             sound_file  \\\n",
      "2013  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "6070  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "2433  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "6504  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "2333  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "...                                                 ...   \n",
      "6792  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "233   data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "3073  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "4475  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "4487  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "\n",
      "                                       spectrogram_file  \n",
      "2013  data/spectrograms/101_1b1_Pr_sc_Meditron_cycle...  \n",
      "6070  data/spectrograms/101_1b1_Al_sc_Meditron_cycle...  \n",
      "2433  data/spectrograms/101_1b1_Pr_sc_Meditron_cycle...  \n",
      "6504  data/spectrograms/101_1b1_Al_sc_Meditron_cycle...  \n",
      "2333  data/spectrograms/101_1b1_Pr_sc_Meditron_cycle...  \n",
      "...                                                 ...  \n",
      "6792  data/spectrograms/226_1b1_Al_sc_Meditron_cycle...  \n",
      "233   data/spectrograms/226_1b1_Al_sc_Meditron_cycle...  \n",
      "3073  data/spectrograms/226_1b1_Ll_sc_Meditron_cycle...  \n",
      "4475  data/spectrograms/226_1b1_Pl_sc_LittC2SE_cycle...  \n",
      "4487  data/spectrograms/226_1b1_Pl_sc_LittC2SE_cycle...  \n",
      "\n",
      "[6898 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# merge the DataFrames on the 'filename' column\n",
    "merged_df = pd.merge(df, data, on='filename')\n",
    "\n",
    "#rearrange columns \n",
    "new_columns_order = ['filename', 'pid', 'cycle_number', 'start', 'end', 'crackles', 'wheezes', 'mode', 'disease', 'sound_file', 'spectrogram_file']\n",
    "merged_df = merged_df[new_columns_order]\n",
    "\n",
    "#sort rows based on patient id then cycle number\n",
    "merged_df = merged_df.sort_values(['pid', 'cycle_number'])\n",
    "\n",
    "# save the DataFrame to a CSV file\n",
    "merged_df.to_csv('data/data_by_cycle.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            filename  pid  cycle_number   start     end  \\\n",
      "0      101_1b1_Pr_sc_Meditron_cycle1  101             1   0.036   1.264   \n",
      "1      101_1b1_Al_sc_Meditron_cycle1  101             1   0.036   0.579   \n",
      "2      101_1b1_Pr_sc_Meditron_cycle2  101             2   1.264   3.422   \n",
      "3      101_1b1_Al_sc_Meditron_cycle2  101             2   0.579   2.450   \n",
      "4      101_1b1_Pr_sc_Meditron_cycle3  101             3   3.422   5.550   \n",
      "...                              ...  ...           ...     ...     ...   \n",
      "6893   226_1b1_Al_sc_Meditron_cycle9  226             9  15.907  18.307   \n",
      "6894  226_1b1_Al_sc_Meditron_cycle10  226            10  18.307  19.964   \n",
      "6895  226_1b1_Ll_sc_Meditron_cycle10  226            10  17.964  19.950   \n",
      "6896  226_1b1_Pl_sc_LittC2SE_cycle10  226            10  17.493  19.436   \n",
      "6897  226_1b1_Pl_sc_LittC2SE_cycle11  226            11  19.436  19.979   \n",
      "\n",
      "      crackles  wheezes mode    disease  \\\n",
      "0            0        0   sc       URTI   \n",
      "1            0        0   sc       URTI   \n",
      "2            0        0   sc       URTI   \n",
      "3            0        0   sc       URTI   \n",
      "4            0        0   sc       URTI   \n",
      "...        ...      ...  ...        ...   \n",
      "6893         0        0   sc  Pneumonia   \n",
      "6894         0        0   sc  Pneumonia   \n",
      "6895         0        0   sc  Pneumonia   \n",
      "6896         1        0   sc  Pneumonia   \n",
      "6897         0        0   sc  Pneumonia   \n",
      "\n",
      "                                             sound_file  \\\n",
      "0     data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "1     data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "2     data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "3     data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "4     data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "...                                                 ...   \n",
      "6893  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "6894  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "6895  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "6896  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "6897  data/Respiratory_Sound_Database/clips_by_cycle...   \n",
      "\n",
      "                                       spectrogram_file  age sex  adult_BMI  \\\n",
      "0     data/spectrograms/101_1b1_Pr_sc_Meditron_cycle...  3.0   F        NaN   \n",
      "1     data/spectrograms/101_1b1_Al_sc_Meditron_cycle...  3.0   F        NaN   \n",
      "2     data/spectrograms/101_1b1_Pr_sc_Meditron_cycle...  3.0   F        NaN   \n",
      "3     data/spectrograms/101_1b1_Al_sc_Meditron_cycle...  3.0   F        NaN   \n",
      "4     data/spectrograms/101_1b1_Pr_sc_Meditron_cycle...  3.0   F        NaN   \n",
      "...                                                 ...  ...  ..        ...   \n",
      "6893  data/spectrograms/226_1b1_Al_sc_Meditron_cycle...  4.0   M        NaN   \n",
      "6894  data/spectrograms/226_1b1_Al_sc_Meditron_cycle...  4.0   M        NaN   \n",
      "6895  data/spectrograms/226_1b1_Ll_sc_Meditron_cycle...  4.0   M        NaN   \n",
      "6896  data/spectrograms/226_1b1_Pl_sc_LittC2SE_cycle...  4.0   M        NaN   \n",
      "6897  data/spectrograms/226_1b1_Pl_sc_LittC2SE_cycle...  4.0   M        NaN   \n",
      "\n",
      "      child_weight  child_height  \n",
      "0             19.0          99.0  \n",
      "1             19.0          99.0  \n",
      "2             19.0          99.0  \n",
      "3             19.0          99.0  \n",
      "4             19.0          99.0  \n",
      "...            ...           ...  \n",
      "6893          16.7         103.0  \n",
      "6894          16.7         103.0  \n",
      "6895          16.7         103.0  \n",
      "6896          16.7         103.0  \n",
      "6897          16.7         103.0  \n",
      "\n",
      "[6898 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "demographic_df = pd.read_csv('demographic_info.txt', sep=' ', header=None)\n",
    "demographic_df.columns = ['pid', 'age', 'sex', 'adult_BMI', 'child_weight', 'child_height']\n",
    "second_merge=pd.merge(merged_df,demographic_df,on='pid')\n",
    "second_merge.to_csv('data/data_by_cycle_and_demographics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pid2 recording_index chest_location acquisition_position  \\\n",
      "0     101             1b1             Pr                   sc   \n",
      "1     101             1b1             Al                   sc   \n",
      "2     101             1b1             Pr                   sc   \n",
      "3     101             1b1             Al                   sc   \n",
      "4     101             1b1             Pr                   sc   \n",
      "...   ...             ...            ...                  ...   \n",
      "6893  226             1b1             Al                   sc   \n",
      "6894  226             1b1             Al                   sc   \n",
      "6895  226             1b1             Ll                   sc   \n",
      "6896  226             1b1             Pl                   sc   \n",
      "6897  226             1b1             Pl                   sc   \n",
      "\n",
      "     recording_equipment cycle_number2                        filename  \n",
      "0               Meditron             1   101_1b1_Pr_sc_Meditron_cycle1  \n",
      "1               Meditron             1   101_1b1_Al_sc_Meditron_cycle1  \n",
      "2               Meditron             2   101_1b1_Pr_sc_Meditron_cycle2  \n",
      "3               Meditron             2   101_1b1_Al_sc_Meditron_cycle2  \n",
      "4               Meditron             3   101_1b1_Pr_sc_Meditron_cycle3  \n",
      "...                  ...           ...                             ...  \n",
      "6893            Meditron             9   226_1b1_Al_sc_Meditron_cycle9  \n",
      "6894            Meditron            10  226_1b1_Al_sc_Meditron_cycle10  \n",
      "6895            Meditron            10  226_1b1_Ll_sc_Meditron_cycle10  \n",
      "6896            LittC2SE            10  226_1b1_Pl_sc_LittC2SE_cycle10  \n",
      "6897            LittC2SE            11  226_1b1_Pl_sc_LittC2SE_cycle11  \n",
      "\n",
      "[6898 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "filenames = second_merge.filename\n",
    "filename_df = pd.DataFrame()\n",
    "\n",
    "filename_df['pid2'] = [re.findall(r'^(\\d+)_', filename)[0] for filename in filenames]\n",
    "\n",
    "#adds the recording index to the data frame\n",
    "recording_index_list = []\n",
    "for filename in filenames:\n",
    "    match = re.findall(r'\\d+_(\\d+[a-z]\\d+)_', filename)\n",
    "    if match:\n",
    "        recording_index_list.append(match[0])\n",
    "    else:\n",
    "        recording_index_list.append(None)\n",
    "filename_df['recording_index'] = recording_index_list\n",
    "\n",
    "\n",
    "chest_location_list = []\n",
    "for filename in filenames:\n",
    "    match = re.findall(r'_([A-Z][a-z])_', filename)\n",
    "    if match:\n",
    "        chest_location_list.append(match[0])\n",
    "    else:\n",
    "        chest_location_list.append(None)\n",
    "\n",
    "filename_df['chest_location'] = chest_location_list\n",
    "\n",
    "\n",
    "\n",
    "acquisition_position_list = []\n",
    "for filename in filenames:\n",
    "    match = re.findall(r'_([a-z][a-z])_', filename)\n",
    "    if match:\n",
    "        acquisition_position_list.append(match[0])\n",
    "    else:\n",
    "        acquisition_position_list.append(None)\n",
    "\n",
    "filename_df['acquisition_position'] = acquisition_position_list\n",
    "\n",
    "possible_recording_equipment = [\"AKGC417L\", \"LittC2SE\", \"Litt3200\", \"Meditron\"]\n",
    "\n",
    "# Create an empty list to store the recording equipment\n",
    "recording_equipment_list = []\n",
    "\n",
    "# Loop through each filename\n",
    "for filename in filenames:\n",
    "    # Extract the recording equipment from the filename\n",
    "    recording_equipment = None\n",
    "    for equipment in possible_recording_equipment:\n",
    "        if equipment in filename:\n",
    "            recording_equipment = equipment\n",
    "            break\n",
    "    \n",
    "    # Append the recording equipment to the list\n",
    "    recording_equipment_list.append(recording_equipment)\n",
    "\n",
    "# Create a DataFrame with the recording equipment list\n",
    "filename_df['recording_equipment'] = recording_equipment_list\n",
    "\n",
    "filename_df['cycle_number2'] = [re.findall(r'cycle(\\d+)', filename)[0] for filename in filenames]\n",
    "filename_df['filename'] = filenames\n",
    "print(filename_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge_df = pd.merge(second_merge, filename_df, on='filename')\n",
    "final_merge_df = final_merge_df.drop(columns=['filename', 'cycle_number2', 'pid2'])\n",
    "final_merge_df.to_csv('data/data_complete.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.7 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "bfe9e5435af0ab44c34ef3869879b94f2b4eaf222b17b3e6cb7962639383bf17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
